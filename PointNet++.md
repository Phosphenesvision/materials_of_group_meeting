# PointNet++ 论文解析

文章：Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J. Guibas: Pointnet++: Deep hierarchical feature learning on
point sets in a metric space. In Advances in Neural Information Processing Systems, pages 5099–5108, 2017.  

作者：Charles R. Qi, Li Yi, Hao Su, Leonidas J. Guibas

链接：https://arxiv.org/abs/1706.02413

本文版权声明：copyright@phosphenesvision

## PointNet++ 大致思想

一共是四个重要的点

第一个点PointNet的不足指出：不能捕捉局部信息，以至于鲁棒性和泛化性较差，借鉴CNN逐层提取特征的思想，重新改进提出了PN的升级版PointNet++。具体可参看3.1节。

第二个点是PointNet++的基本结构，①第一对点云集进行采样，生成一个又一个的小的局部区域；②第二是进行重新的组合，重新组合后的点云集就拥有了与周围点的交互信息；③第三个是特征提取层，对集合好的点集进行特征提取，输出特征。具体可参看3.2节。

第三点是对PointNet++的补充，针对于每一个局部区域内可能存在点稀疏和点稠密的情况，因此各个区域大小的选取也是不尽相同的，本文提出了MSG和MRG两种算法来解决这个问题，具体可参看3.3节。

第四点是对于分割问题，输出点云和输入点云的大小不一致，这个时候需要引入反卷积结构，并且用一个跳跃结构综合特征提取前和特征提取后的信息，具体可参看3.4节。

## PointNet++ 详细阅读

以下的部分不是对于论文的简单翻译，而是在理解的基础上对论文各部分又做的局部性总结，个人认为第二部分和第三部分是重点。

### 0 摘要

1. 以前的PointNet有劣势：劣势就是PointNet不能捕获局部信息，因此在识别细粒度模式时表现较差，而且泛化能力也比较差。
2. 因此设计了PointNet++，PointNet的大致结构是一种层次神经网络，迭代的应用PointNet网络。
3. 该网络有两个特点，第一个特点就是为了解决不能捕获局部信息的问题，方法就是应用了度量空间距离(metric space distance)。
4. 第二个特点是针对于另外一个问题：很多点集是在不同密度上进行采样，所以如果训练集是在相同密度上进行采样的话，效果就会显著下降。解决的办法是提出了一个集合学习层(set learning layers)，这个学习层可以融合不同密度规模上的特征。

### 1 介绍

1. 第一段，介绍了一下点集的一些相关情况：点集是欧几里得空间上的一些点的集合，点集应该至少满足两个特性，①是对于旋转或其他操作(permutation)的不变性；②是用到距离策略，可以知道周围点的一些特性，比如密度特性。这两个特性在PointNet中都提到了，不是什么新的东西。

2. 第二段，回顾PointNet：PN的基本的思想是直接对点云数据进行处理，通过网络学习点云中每一个点的空间特征，最后再把所有点的空间特征合起来组成全局特征。这样的做法弊端是这个网络不能捕捉局部的信息，局部信息可以理解为与周围点的交互。弊端在摘要中也说了，第一个处理细粒度的点云时效果较差，第二个是泛化能力较差。

3. 第二段后半部分，回顾CNN中是怎么处理这个问题的：CNN是采用多种像素的层次网络来处理这个问题的，multi-resolution hierarchy。比较低级的神经元层的感受野更小，而比较高级的神经元层的感受野比较大。

4. 第三段，介绍PN++网络的主要思想：收到了层次网络的启发，PN++也是用的层次网络，实现过程：①首先根据距离策略把整个点集的输入分成一个个局部区域，这些区域之间有重叠，且由于这些区域有重叠，所以在后面的处理过程中，权重也是共享的；②然后从这些局部区域中去提取局部特征；③再将所有的局部特征整合组成全局特征。

5. 第四段和第五段和第六段，再细细分析PN++网络：刚才的三个步骤中第三个步骤比较好理解，但是其他两个步骤都有些问题，①如何把点集分成一个个局部区域，阐述第一个问题，如何分割一个个局部区域，这些局部区域用两个参数来表示，质心位置(centroid location)和大小(scale)，质心的选取是用最远点采样的方法(furtest point sampling  -- FPS)，这些局部区域的感受野是不一样的，它们受到输入大小和算法策略的影响，这种感受野的设置使网络更有效且更高效；关于大小的选取，不能盲目的去模仿图像数据，图像数据中的局部区域的大小其实就可以理解成滤波器的大小，一般是越小越好，而点云数据与之相反，越大越好；

   > 可以展开来说明一下这个相反性的问题，在图像的数据中，像素点并不涉及一个密度不同的问题，就是说所有的像素都是均匀的落在图像格子中的(grid)，所以有研究证明滤波器越小，结果越精确，而在点云数据中则需要考虑这个密度的问题，有的地方点特别多，有的地方点特别少，如果采用比较小的scale的话，可能捕捉不到足够的信息，从而对后续网络的处理产生很大的困扰。
   >
   > 参考论文：K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition.
   > arXiv preprint arXiv:1409.1556, 2014.  https://arxiv.org/abs/1409.1556
   >
   > 参考图片：同一场景的RGB图和点云图，![PN++-F1](image\PN++-F1.png)。

   ②如何从局部区域提取局部特征，用PointNet去提取局部特征，PN在提取局部特征时具有很多优点，比如处理无序点集有效，鲁棒性较强等等。因此，PN其实是被PN++当成了网络的一个block，迭代处理所有的局部区域。

6. 第七段，本文的主要贡献：提出了一种提取局部特征的方法，训练时用到了dropout，最后的实验表明，该网络性能较好，efficient，effective and robust，且超越了目前最好的网络。

### 2 问题描述

假设$\chi = (M, d)$是一个离散度量空间(discrete metric space)，并且就把这个当成是网络的输入，其中M是普通的欧几里得空间上的点云集，包含很多个点，每个点有自己的特征向量，d是该空间的距离度量(distance metric)。

我们要做的就是通过网络学到一个函数f，这个f可以是一个分类任务的函数，对整个输入点云数据预测一个输出种类；也可以是一个分割人物的函数，对输入点集中的每一个点都预测一个输出种类。

### 3 方法论

PointNet++可以看成是PointNet的延申

#### 3.1 回顾PointNet

假定输入点集为$\{ x_1, x_2, ... , x_n\}$，每一个x都是欧几里得空间里的一个点，PointNet要完成的事情就是求得一个函数f，把点集$\{ x_1, x_2, ... , x_n\}$变成一行向量，也就是提取出整个点集的特征来，其中f的学习参考公式：$f(x_1, x_2, ... , x_n) = \gamma(\max _{i=1,2,...,n} \{ h(x_i)\})$。其中γ和h都是一个多层感知机网络MLP。

h可以视作是对单个的点做一个编码操作。

f函数的要求有：①必须满足数学转换不变性(permutation invariacne)，②基本可以拟合所有连续的点集。

#### 3.2 介绍PointNet++的网络结构

首先来看整体的网络结构：![PN++-F2](image\PN++-F2.png)。

看左边是基础网络backbone，右边是去实现具体的任务。

首先来介绍基础的网络backbone，这个是由一系列的集函数提取层组成的，从图中看应该是两个提取层，可以看出，输入点云大小为$ N * (d+C)$，经过第一个集函数提取层点云大小变成$ N_1 * (d+C_1)$，再经过一个提取层点云大小变成$ N_2 * (d+C_2)$。N代表点云中点的数量，d代表点的坐标，C代表点的其他特征向量。

集函数提取层中包含三个关键的操作，分别是采样层，整合层和PointNet层。

1. 采样层：对点集$\{ x_1, x_2, ... , x_n\}$进行FPS采样得到$\{ x_{i1}, x_{i2}, ... , x_{im}\}$，这个集合就是每一个局部区域的质心点，这也说明了我们要从原始的输入点集中得到m个局部区域；至于生成的局部区域的scale，我们用一种基于数据的方法(data dependent manner)来确定这个参数。

   > 介绍FPS最远点采样
   >
   > FPS的算法操作是这样的：①在一个点集A中任意选择一个点，组成点集B，A中删除该点；②在A中剩下的每个点都求出它到B点集中的每个点的最小距离，当成该点的值，然后综合A中所有的点，求出最大的那个点放到B中，A中删除该点；③重复这个过程，直至B中点的个数满足要求。

2. 整合层：该层的输入有两个，一个是原始点集$\{ x_1, x_2, ... , x_n\}$，大小为$ N * (d+C)$，前面已经介绍过了，第二个是质心点集$\{ x_{i1}, x_{i2}, ... , x_{im}\}$，大小为$N^{'} * d$，N'代表质心点集的点的个数，d代表它们的坐标；输出是$ N^{'} * K * (d+C)$，K的含义是局部区域中的点的个数，其他字母的含义同上，注意对于不同的区域K的值也是不同的，K的值与局部区域的半径有关，如前所述，局部半径是变化的，而局部半径是度量距离所确定的。

   那么如何找到一个局部区域内的所有点呢？一共有两种方法，①ball query方法：以质心为局部区域的圆心，做半径划球，该区域内的所有点都被划到这个局部区域中来；②kNN方法：划定K个与质心距离最近的点作为采样区域。这两种方法各有优劣，一般来说，如果做语义分割则采用ball query的方法。

3. PointNet层，充当了特征提取的作用：本层的输入是$ N^{'} * K * (d+C)$，输出是$ N^{'} *  (d+C^{'})$，前面说过K的值可能不尽相同，所以首先要把输入顾定成一个确定的长度，然后通过PointNet来提取特征，得到最后的输出。

   需要注意的一点是，我们用于PointNet处理的d并不是点的真是维度，而是相对于质心的位置，具体来说是对于每一个点都有$x_i^{(j)}= x_i^{(j)} - \hat{x}^{(j)} , i = 1; 2;...; K , j = 1; 2; ...; d   $，经过这样的操作，这就保证了局部空间里各个点之间的交互。

#### 3.3 PN++细节补充：阐述PointNet++对于分布不均匀点的鲁棒性

不同的局部区域中的点的密度是不同的，这就要求我们对不同的区域进行特征提取的方法也应该是不同的，前面也说到过，由于采样过程可能对系数点集造成信息缺失，因此我们要注意不能再去寻求小区域特征，转而应该寻求大区域特征。

不同于3.2节的特征提取层只能提取一个确定的scale的输入点云，我们对PointNet进行改动，使它可以提取不同scale的点云输入，怎么实现的呢，用到了两种不同的可适应密度处理层。相关展示图如下：

![PN++-F3](image\PN++-F3.png)。

1. MSG Multi-Scale Grouping，多scale聚合层：对于每一个scale的grouping层提取特征，然后再将这些特征拼接起来。但是在训练的过程中用到了dropout的方法，这个方法在CNN中很常见，但是再点云网络中却不是那么常见，具体来说使从[0, p]中等概率的选择一个概率值θ ，对于每个输入点云图中的点，都是以θ 概率被抛弃；再测试时则去掉了dropout层。这样做的好处是，可以选择不同大小的θ  来模拟不同密度的点云输入图。

   但是MSG有自己的缺点，计算量巨大，因为它是对每一个采样出来的局部区域都做一个PointNet特征提取，涉及到了大量的工作，尤其是在底层中，采样层采样出来的大量的局部区域，更增大了训练量。

2. MRG Multi-Resolution Grouping，多分辨率聚合层：MSG的计算量特别大，因此提出了更进一步的MRG，MRG的示意图如b所示，输出结果向量包含两个部分，第一个部分是左边这个向量，是提取的前一层子区域的特征；第二个部分是右边这个向量，是对当前子区域的特征提取。

   当当前子区域比较稀疏的时候，左边一个向量的权重应该小一点，右边一个向量的权重应该大一点，因为左边的权重经历的更多一次的采样，会损失更多的信息；而当前子区域比较密集的时候，左边一个向量的权重应该大一点，右边应该小一点，因为前面一个向量由于经历少一次采样卷积，会拥有更高的分辨率，包含更多信息。

   MRG的方法计算量要小，因为它避免了在低维卷积层上做特征提取。

#### 3.4 更多的细节补充：分割算法的特征提取策略

普通的卷积操作毫无疑问会使输入点云变小，而分割算法的输出大小则要求与输入具有相同的大小，那么应该如何来解决这个问题呢，一个很容易想到的想法就是说将每一个点都视作一个单独的子区域，这样就不会造成大小的压缩了，但是这种做法发毫无疑问会大大增加计算开销。因此我们用反卷积的方法来完成分割任务。正着传播叫做特征提取层(set abstraction level)，从Nl-1到Nl层，这个卷积层使输出大小小于输入大小，反着传播叫做特征传播层(point feature propagation level)，从Nl层到Nl-1层，这个层使输出大小大于输入大小。实现方法是插值法(interpolating)，对输入数据Nl层进行插值，一直插值到输出数据Nl-1层的大小停止。插值的方法有很多种，本文用到的是inverse distance weighted average based on k nearest neighbors  ，反距离权重平均插值法，操作方法是这样的，对于每一个需要进行插值的点，选取它最近的k个点，对它们的特征值与权重求平均，得到的值当做该点的特征替代值，其中权重用距离的平方反比来衡量，公式为$f^{(j)}(x) = \frac{\sum_{i=1}^{k}\omega_i (x) f_i^{(j)}}{\sum_{i=1}^{k}\omega_i (x)}, \omega_i(x) = \frac{1}{d(x,x_i)^p},j = 1,2,...,C$。得到Nl-1层的大小之后，再用一个跳跃的结构与前面真正的Nl-1层拼接起来，得到一个拼接以后的特征向量，在经过"unit pointnet"卷积（类似于CNN中的1 * 1卷积），全连接层，ReLu激活函数层来更新特征向量，这个过程一直重复，到与原始输入点云大小相同为止。

### 4 实验过程

对于分类任务，衡量标准是准确度；对于分割任务，衡量标注是平均体素准确度，即求出每一个提速的准确度，再做平均，具体参考论文A. Dai, A. X. Chang, M. Savva, M. Halber, T. Funkhouser, and M. Nießner. Scannet: Richly-annotated 3d reconstructions of indoor scenes. arXiv preprint arXiv:1702.04405, 2017.  https://arxiv.org/abs/1702.04405。

数据集用了四个：

1. MNIST数据集，充当二维目标检测：是一些手写的数字识别的图像数据集，包含60k训练图像和10k测试图像。
2. ModelNet40数据集，充当三维刚性目标检测：包含40类CAD模型，大部分是人工标注的，用到了其中9,843个shape做训练集，2,468个shape做测试集。
3. SHREC15数据集，充当三维非刚性目标检测：包含50个类，1200个shape，每一类有24个shape，大部分是自然界中存在的物体，包含马，猫等等，还用到了5折的训练算法策略提高模型的精确度。
4. ScanNet数据集，充当三维场景识别：1513经过扫描和重建的室内场景，1201个场景来训练，312个场景来测试。 

#### 4.1 分类任务的训练

用到了MNIST数据集和ModelNet40数据集，MNIST中的图片转换成512个点云中的点，ModelNet40数据集转换成1024个点云中的点，相关结果如图所示，

![PN++-T1T2](image\PN++-T1T2.png)

其中PointNet表示是普通的PointNet网络，PointNet (vanilla) 表示的是PointNet网络但是去除掉转换网络层，ours表示本文提出的PointNet++网络，ours normal  表示本文提出的PointNet++网络但是用了5000个点作为输入。

鲁棒性分析

为了测试鲁棒性，测试集特地选取了几个不同采样点数量的测试数据，相关的结果如下图：![PN++-F4](image\PN++-F4.png)。DP的意思是dropout，SSG的意思是single scale grouping。

#### 4.2 分割任务的训练

为了与其他网络实现统一，我们移除了Scannet数据集中的所有的RGB信息，并且把点的预测改成了体素预测，实验结果如图：![PN++-F5](image\PN++-F5.png)。

可视化结果如图：

![PN++-F6](image\PN++-F6.png)。

鲁棒性分析

鲁棒性分析的结果预测在上二图中可以看到。

#### 4.3 非欧几里得策略空间的分类任务

本届主要考验该网络的泛化能力，首先构建以pairwise geodesic distance为基础的策略空间，然后提取内在特征，包括WKS，HKS，和多层高斯曲率(multi-scale Gaussian curvature )。然后用这些特征作为输入，提取这些内在的特征就可以是使网络不受外在形状的影响，比如下图这种情况：

![PN++-F7](image\PN++-F7.png)。

其他的一些思想也可以起到相同的作用，比如XYZ坐标和用到欧几里得空间特征，但是本文选用的方法可以证明是最好的方法。对比结果图为：

![PN++-T3](image\PN++-T3.png)。

#### 4.4 特征可视化

这是在ModelNet40的第一个卷积层的训练结果，表示网络学习到的特征，红色代表最近，蓝色代表最远。操作过程是把点云集分成一个又一个的体素格子，然后每个体素格子展示对神经元激活贡献度最高的100个点。

![PN++-F8](image\PN++-F8.png)

### 5 相关工作

我们的工作是受到了CNN的启发，但是CNN并不能直接用在无序点云上面。

以前的工作没有考虑到潜在的距离度量的影响，因此很难提取局部特征，而本文提出来的网络则考虑了距离度量空间，因此就可以提取局部特征了，对结果是一个正向的作用。

还有一个问题是稀疏度不均匀的问题，以至于在选取scale的时候非常困难，以前的工作经常忽略这一点，而我们的网络则通过端到端的网络提取特征，平衡了各种大小的scale，解决了这个问题。

### 6 结论

①第一段，总结这篇文章：本文处理采样的点云集非常高效，而且又引入了MSG和MRG去解决点云稀疏度不均匀的问题。

②第二段：对于未来的展望：第一个是提速，尤其是对MSG和MRG的提速，可以通过让它们共享更多的共享权重实现。第二个是要找到一个具体的应用，在这里CNN不起作用本文的网络起作用的情况，可能能在高维空间中找到。