# 组会讲稿

FPS

T-NET

3D Object Detection

对比算法

证明过程

## 1 点云数据目标检测综述

在上次组会总结之后，我又调研了一些点云数据进行目标检测的发展历史，希望能够从根本上了解用点云数据进行目标检测的原理。

首先是说点云数据与图像数据的相同与不同：相同点很简单，它们都可以用来感知周围的环境，而不同点虽然可以杂七杂八分出很多种类，但是核心的基本点其实就一个，那就是一般情况下，点云数据的精确性要大于视觉图像，举一个例子来说，例如图片中存在遮挡和近大远小的问题而点云上则没有这些问题。

展开这一个点来讲，激光雷达原理和数据特点，

首先来讲激光雷达的原理，激光雷达这个单词是**li**ght **d**etection **a**nd **r**anging的缩写，光学检测与测距，

以威力登VLP-16为例，VLP-16是16线的雷达，16线的意思是说雷达由16个laser单元组成，每一个laser单元是由激光发射器和接收器组成，除了16线雷达之外，常见的还有单线、4线、16线、32线、64线和128线雷达。

大体来说，雷达工作时进行每秒 18000 次的旋转来探测周围的环境， 每一个激光发射器发射红外光时， 在碰到障碍物的时候就会发生反射， 探测器接收到相应的信息后就可以计算出周围的环境信息 。

具体来说，在某一个时刻，并不是每一个laser单元一起发射激光束，而是每个 laser 轮流工作， 工作时间为 2.034μs， 除此之外还有一个空缺的时间18.432μs 用于充电， 也就是每个工作的周期是(16*2.304μs) + 18.432μs= 55.296 μs。工作的频率大概是18.08kHz， 用周期图来表示就是下面的这个样子。  

接下来就是雷达到底测量到了什么数据？

从这个图中来看的话，一个数据包包含1248个字节，首先是包含包括 42 个 UDP 首部（ 实际上这个 UDP 首部是 Ethernet+IP+UDP）， 4 字节 time stamp， 2字节 factory bytes ，time stamp： 在一个 packet 中的专门四个字节中存储， 用来表示机器运行了多少毫秒， 数值是 0- 3,599,999,999，time stamp 应该与 GPS 配合使用。factory bytes： 一共两个字节， 每个 packet 中只有一次， 表示 mode 和 product ID  

剩下的1200字节时这样的，雷达的运行周期时55.296μs，雷达每两个运行周期称之为一个数据段data block，12个数据段称为一个data packet数据包，也就是雷达运行24个周期后，所有暂存的数据才会一起打包传输回服务器。每个data block包含100个字节数据， 其中开头两个固定字节0xFFEE，紧接着是一个两字节的 azimuth 数据， 用来表示 laser 所处的角度值， 转速： 转速可以任意设置 300rpm 至 1200rpm 之间， 梯度增长为 60rpm。  ，方位角的计算公式是这样的，不同的转速对应不同的方位角增长率，300 0.1° ； 600 0.2° ； 900 0.3° ； 1200 0.4°  ，方位角分别用 0-35999 来表示 0° 至 359.99° ， 剩下的 96 个字节就是用来存储 32 个data point数据点数据， 每个 data point 包含三个字节：一个数据点是每一个 laser 测量并返回来的数据， 一共是 3 个字节， 其中两个字节用来表示距离（distance），间隔尺寸是 2mm， 也就是说真实的距离数据等于返回值*2mm，另外一个字节用来表示校准反射率（calibrated reflectivity）， Diffuse reflectors 的反射用 0-100 来表示反射率从 0%-100%， 而 Retro-reflectors 则用 101-255 来表示反射率， 255 表示理想反射。但是如果一个 laser 没有测定到数据， 那么它的 data point 将是 3 个字节的 0 元素。  。  

 位置包（position packet） 传输： 数据包每传输 14 次位置包进行一次传输， 每个 position packet是 551 字节，  position packet 传回的数据主要与 GPS 的应用和坐标变换相关。  

## 1.1 前言

在前言部分，首先来介绍一些体素和网格的概念，之所以介绍体素和网格，是因为在后面的讲解中我们会提到体素的结构个网格的结构，

体素或立体像素(voxel)，是体积像素(volume pixel)的简称。概念上类似二维空间的最小单位——像素，像素用在二维电脑图像的视频数据上。体积像素一如其名，是数字数据于三维空间分区上的最小单位，应用于三维成像、科学数据与医学视频等领域。有些真正的三维显示器运用体素来描述它们的分辨率，举例来说：可以显示512×512×512体素的显示器。

如同像素，体素本身并不含有空间中位置的数据(即它们的座标)，然而却可以从它们相对于其他体素的位置来推敲，意即它们在构成单一张体积视频的数据结构中的位置。

多边形网格（Polygon mesh）是三维计算机图形学中表示多面体形状的顶点与多边形的集合，它也叫作非结构网格。

这些网格通常由三角形、四边形或者其它的简单凸多边形组成，这样可以简化渲染过程。但是，网格也可以包括带有空洞的普通多边形组成的物体。

非结构网格内部表示的例子有：

一组顶点的简单列表，它们带有表示那些顶点组成多边形的信息列表；另外可能带有表示空洞的附加信息。
顶点列表 + 边界列表（一对索引信息）+ 连接边界的多边形列表
翼边数据结构
根据应用程序的不同所选择的数据结构也有所不同：三角形的处理要比普通多边形的处理更加简单，尤其是在计算几何中更是这样。对于优化的算法，可能需要快速访问边线或者相邻表面这样的拓扑信息，这样就需要如翼边表示这样更加复杂的结构。



第二个要介绍的是一个算法FPS算法，这个在我上周的论文中也涉及到了，主要是对于点集的采样，这周在后面也会有介绍，所以暂且在这里提一下，

简介
在 PointNet++ 中用到了FPS(Farthest Point Sampling) 最远点采样法，该方法比随机采样的优势在于它可以尽可能的覆盖空间中的所有点。

实现步骤
假设一共有n个点,整个点集为N = {f1, f2,…,fn}, 目标是选取n1个起始点做为下一步的中心点:

随机选取一个点fi为起始点，并写入起始点集 B = {fi};
选取剩余n-1个点计算和fi点的距离，选择最远点fj写入起始点集B={fi,fj};
选取剩余n-2个点计算和点集B中每个点的距离, 将最短的那个距离作为该点到点集的距离, 这样得到n-2个到点集的距离，选取最远的那个点写入起始点B = {fi, fj ,fk},同时剩下n-3个点, 如果n1=3 则到此选择完毕;
如果n1 > 3则重复上面步骤直到选取n1个起始点为止.

最后一个需要介绍的是豪斯多夫距离Hausdorff Distance

Hausdorff距离是一个衡量两个点集之间的距离的一个函数，它的定义是这样的，
$$
Hausdorff = MAX\{MAX_{x\in X} MIN_{y \in Y}d(x,y), MAX_{y\in Y} MIN_{x \in X}d(x,y)\}
$$
具体的操作过程是这样的，首先对于X集合中的所有点xi，分别求出xi到Y集合中的每个点的距离，再将所有的xi取出来，求它们的最小值，对于Y集合同样这样做，最终求它们两个的最大值当成最终的结果。

Hausdorff距离的意义是用来衡量两个点集之间任何距离点的最大的不匹配度，对于X集合来说，得到X集合的距离最大值之后，便有，任意X中的点以该半径画圆，至少能有一个Y集合中的点能落在该圆中，也就是说，其实Hausdorff距离不关心是否每个点都落在该圆中，只要有一个点落在这个圆中即可，也印证了两个点集的最大不匹配度。

## 2 PointNet总结

### 2.0 前论

下面来介绍一下点云目标检测的主要的成果之一，PointNet，PointNet是在2017年CVPR上由斯坦福大学的Charls博士发表，它的最主要的特点就是直接处理点云数据，之前我们也介绍了，以前的做法主要是将点云图转化成体素图，然后对体素图进行借鉴原来的CNN的卷积，提取相应图像特征，然后进行分类和分割任务

。目前采用的方式主要有两种：

> 1、将点云数据投影到二维平面。此种方式不直接处理三维的点云数据，而是先将点云投影到某些特定视角再处理，如前视视角和鸟瞰视角。同时，也可以融合使用来自相机的图像信息。通过将这些不同视角的数据相结合，来实现点云数据的认知任务。比较典型的算法有MV3D和AVOD。
>
> 2、将点云数据划分到有空间依赖关系的voxel。此种方式通过分割三维空间，引入空间依赖关系到点云数据中，再使用3D卷积等方式来进行处理。这种方法的精度依赖于三维空间的分割细腻度，而且3D卷积的运算复杂度也较高。

不同于以上两种方法对点云数据先预处理再使用的方式，此论文的作者提出了**直接**在点云数据上应用深度学习模型的方法，称为PointNet。

### 2.1 问题描述

首先来描述一下我们整个网络的工作流程，网络的输入是未经处理过的点云数据，很多个点组成了一个集合输入到网络中，每个点由特征向量来表示，特征向量中包含该点的xyz坐标，颜色等相关信息，但是一般我们只考虑xyz坐标信息，忽略其他信息。

对于一个分类网络来说，输入就是直接输入这些未经处理的点云数据集，输出是一个k维的score向量，表示该点云集是每一类数据的可能性和概率。对于分割任务，又可以分成局部分割和全景分割，局部分割的意思是对一个物体进行分类，分类出它们的各个部位，而对于全景分割，通常是给出一个场景，分割出该场景中的每一类物体，但是这两种情况的输出都是一样的，输出是一个n * m的矩阵，分别来表示n个点中的m个类别的归属结果。

### 2.2 深刻剖析点云数据特点

点云数据是在欧式空间下的点的一个子集，它具有以下三个特征：

- 首先是第一个属性：无序性，这也是最重要的属性。无序性的定义是说，点云本质上是一长串点（nx3矩阵，其中n是点数）。在几何上，点的顺序不影响它在空间中对整体形状的表示，例如图中，相同的点云可以由两个完全不同的矩阵表示，但是再正常的输入之中，如果再惨杂进无序性这个特点，那么数据就会受到影响了，如果一个点云图中有N个点，那么可能产生的输入就有N!种，因此我们希望得到的效果如下图右边：N代表点云个数，D代表每个点的特征维度。不论点云顺序怎样，希望得到相同的特征提取结果。而采用什么方法来做呢，就是采用一种平衡策略来平衡掉这种无序性，pointnet采用了max-pooling策略。我们知道，网络的一般结构是：提特征-特征映射-特征图压缩（降维）-全连接。下图中x代表点云中某个点，h代表特征提取层，g叫做对称方法，r代表更高维特征提取，最后接一个softmax分类。g可以是maxpooling或sumpooling，也就是说，最后的D维特征对每一维都选取N个点中对应的最大特征值或特征值总和，这样就可以通过g来解决无序性问题。

- 第二个属性是点与点之间的空间交互关系。一个物体通常由特定空间内的一定数量的点云构成，也就是说这些点云之间存在空间关系。点云并不是单独的一个个点，而是与周围点有一个交互信息：所有空间中的点都不是孤立的，它们与周围的点是有一个交互的，从而组成不同的物体形状，我们用距离来表示这个交互信息，对于网络来说，我们需要能够捕捉点与点之间的这个交互信息；为了能有效利用这种空间关系，论文作者提出了将局部特征和全局特征进行串联的方式来聚合信息。

- 第三个属性是不变性。点云数据所代表的目标对某些空间转换应该具有不变性，如旋转和平移。也就是说对于这些点集对于一些数学变化来说应该是保持不变性的，比如说旋转操作就不应该改变点云的种类或者点云的语义。这个问题可以通过STN（spacial transform netw）来解决。二维的变换方法主要是引入了重采样操作，三维不太一样的是点云是一个不规则的结构（无序，无网格），不需要重采样的过程。pointnet通过学习一个矩阵来达到对目标最有效的变换。具体来说，论文作者提出了在进行特征提取之前，先对点云数据进行对齐的方式来保证不变性。对齐操作是通过训练一个小型的网络来得到转换矩阵，并将之和输入点云数据相乘来实现。

- 无序性：这是点云相当重要的一个性质，什么意思呢，借用引用链接的解释，无序性的定义是说，点云本质上是一长串点（nx3矩阵，其中n是点数）。在几何上，点的顺序不影响它在空间中对整体形状的表示，例如图中，相同的点云可以由两个完全不同的矩阵表示，但是再正常的输入之中，如果再惨杂进无序性这个特点，那么数据就会受到影响了，如果一个点云图中有N个点，那么可能产生的输入就有N!种，因此我们希望得到的效果如下图右边：N代表点云个数，D代表每个点的特征维度。不论点云顺序怎样，希望得到相同的特征提取结果。具体的实现策略可以看4.2.1节。

- 点间交互性：点云图中的点云存在于一个距离测量空间中，在这个空间中，所有的点都不是孤立的，而是可以与周围的点形成一个局部区域，这个局部区域是有意义的，这也就要求我们的网络能够提取出相应的局部特征。

  > 在这里稍微提一下，虽然本文中提到了局部区域，但是点的表示只是用一个三维坐标来表示的，这根本无法如文中所说可以捕捉局部特征，因此本文中提出的PointNet网络并没有很好的提取局部特征的能力，而它的升级版PointNet++则着重于解决这个问题，具体参看PN++的文章。

- 刚性变换不变性(invariance under transformations)：这一个特性很好理解，就是说对于这些点集对于一些刚性变换来说，比如旋转和平移，虽然点的位置和坐标会发生变化，但是内在特性应该是保持不变性的，比如类别信息和语义信息。具体的实现策略可以参考4.2.3小节。

### 2.3 在剖析点云数据特点后分析网络结构

根据结构图，首先来看网络来分析该网络，然后再来补充细节。

1. 输入是一个n * 3的点集，n代表点的个数，3代表每个点的特征，该网络只用到了坐标信息，因此是xyz三维特征。
2. 第一次输入变换，对空间点云进行调整，旋转出一个更容易用于分类或者分割的角度，比如把物体转到正面，这一步操作就涉及到了点云的第三个特性，刚性变换不变性，具体的操作方法可以参考后面的细节补充。
3. 接下来是一个MLP去对特征进行学习，输出变成n * 64。
4. 第二次输入变换，对提取出的64维特征进行对齐，即在特征层面对点云进行变换，同样涉及到了刚性变换不变性。
5. 接下来仍然是特征提取，输出变成n * 1025。
6. 然后是一个最大池化的操作，提取出点云集全局特征，该操作与点云的无序性相呼应，具体操作方法可参考4.2.1节。
7. 对于分类网络来说，提取完全局特征后，就可以训练一个MLP得到最后的输出了。
8. 对于分割网络来说，全局特征还要与前面的特征进行融合，详细可见4.2.2节，再通过两个MLP的特征提取，才能得到最后的输出结果。
9. 总体来说，该网络的骨架网络包括两次刚性变换，两次特征提取，一次无序性最大池化平衡策略，对于分类网络来说，再进行一次MLP特征提取即可得到输出结果，而对于分割网络来说，还需要一次跳跃结构的辅助和两次MLP特征提取才可以得到最终的结果。



 ###### 4.2.1 针对于点集无序性的平衡策略

在前面已经阐述了无序性的定义，网络结构需要处理这种无序性，也就是无论输入点集中点的顺序如何，输出结果应该是相同的，望楼的这种能力也是处理在原文中本小节阐述了三种相应的方法，分别是①将输入点集按照一个规范的顺序进行排序；②把输入当成一个序列，按照训练RNN的方法来训练网络，但是需要做一个数据增强，提前将所有可能的刚性变换全部考虑到；③设计一个平衡函数，将所有的点通过这个平衡函数结合起来。

本文采取的是第三种算法，因此前两种算法不再详细介绍，值得注意的是平衡函数有很多种，加法运算 + 和乘法运算 * 都可以看作是一个平衡函数，我们设计的平衡函数需要满足的要求是如下这个公式
$$
f ( \{x_1, x_2, ..., x_n\}) \approx g(h(x_1), h(x_2), ..., h(x_n))
$$
本文的想法是用g函数去近似f函数，f函数是网络的原函数，是定义在初始点云集合上的，g函数是是一个平衡函数，是定义在初始点云集合提取的特征上的，h函数是一个多层感知器网络MLP，用于对初始点云集合提取特征。

具象来说，选取的平衡策略函数g，特征提取函数h等等这些函数的组合应该是要逼近网络的预期效果f。

而本文选取的g函数就是一个简单的最大池化层函数，回顾刚才的网络模型，输入进最大池化层的是一个n * 1024的张量，而输出的则是1 * 1024的张量，这便是最大池化层的效果。一个更为形象的图是这样的：

尽管最大池化的平衡策略看起来很简单，但是理论分析4.3节和实验结果5.2.1节都表明了该函数的有效性和高效性。

###### 4.2.2 分割任务中的跳跃结构

本文的PointNet网络的骨架结构输出是一个经过最大池化的一维向量，这个向量可以被看作是输入点云集的全局特征，对于分类任务来讲，再去训练一个SVM分类器或者MLP分类器即可得到输出结果，而分割任务则不是这么简单，分割任务需要用一个跳跃结构将该全局特侦与之前的局部信息结合起来，再去经过分类器去训练分类的语义值。

这样对于网络的改变从实验结果来看是起到了一个正向的作用。

###### 4.2.3 针对于刚性变换不变性的校准网络

本小节对应的是点云的第三个特征，刚性变换不变性

首先同样是给出了一个对比算法，是在特征提取之前把所有的输入数据集排列到一个规范空间。

但是本文的做法是训练一个小网络T-net，用这个T-net去预测一个放射变换矩阵(affine transformation matrix)，然后让其与原坐标向量进行相乘。这样得到的结果不仅达到了刚性变换的目的，还保持了刚性变换的不变性，虽然这个T-net很小，但是它和大的网络的网络结构相似，由很多基本的小的单元组成，这些小的单元包括独立的点特征提取层，最大池化层和全连接层。

回过头来再看网络的整体结构，我们一共用了两次T-net去保持矩阵的刚性变换不变性，刚才是阐述了作用坐标空间的T-net，也就是第一次用到的T- net，而第二次用到T-net是作用在特征空间，事实上，特征空间同样可以用到T-net去做保持刚性变换的不变性，但是特征空间的维度要比坐标空间多，需要考虑更多的问题，网络优化的难度也会变大，因此需要加一个正则化公式到最终分类层softmax训练的损失上，具体来说是$ L_{reg} = ||I - AA^{T}||_{F}^{2} $，A就是通过T-net预测出来的特征转换矩阵，还可以人为约束特征转换矩阵是一个正交矩阵，这个操作可以避免输入内容的信息损失，这样优化过程就变得更加稳定，我们的网络也有一个更好的性能表现。

对比试验结果在5.2.2节

### 2.4 理论分析

本节主要是说明两个定理

1. 逼近定理：这个定理针对的还是4.2.1节的平衡策略，也就是说，这个定理证明了MAXPOOLING函数可以当作是一个平衡函数。定理的内容是说
   $$
   假设f函数是一个定义在Hausdorff \  distance的连续的集函数f: \chi \rightarrow R，\chi是一个点集的定义域，R是一维实数空间值域，\\ 那么有如下结论：\forall \epsilon >0，必然存在一个连续集函数h和一个平衡函数g(x_1, x_2, ..., x_n)=\gamma \circ MAX使得对于任意的S\in \chi,有 \\ \mid f(S) - \gamma(MAX_{x_i \in S}(h(x_i)))\mid < \epsilon \\
   其中S=\{x_1, x_2, ..., x_n\}，\gamma是一个连续函数，MAX是最大池化操作
   $$
   那么首先来理解一下这个定理，定理种的f函数就是整个PointNet网络，h函数就是对于每一个点集中的点做的特征提取函数，MAX对应平衡策略最大池化层的操作，γ  是最后的分类层训练的多层感知机。同时证明了最大池化层的维数越大，提取的信息越为精确。

2. 瓶颈定理：这个定理与整个网络的鲁棒性有关，实验测试参考5.2.3节，定理的内容是说
   $$
   假设用u函数来代表对称函数，因此有u=MAX_{x_i \in S}(h(x_i))，函数u定义在 \chi \rightarrow R^K，\chi是一个点集的定义域，R^K是K维实数空间值域，\\ f则可以表示成f = \gamma \circ u,那么有如下两个结论：① \forall S, \exist C_S, N_S \subseteq \chi, f(T) = f(S) ,if C_S \subseteq T \subseteq N_S; ②\mid C_S \mid \leq K.
   $$
   第一个定理表明，对于输入点集S来说，如果发生一定程度的信息丢失，或者一定程度的噪声干扰，也不会影响分类标签和分割标签的预测，只要它不超过信息丢失的临界点Cs(Critical Points)和噪声干扰的临界点Ns(Upper-bound Points)，这也表明了网络的鲁棒性，能够忍受一定程度的信息丢失和噪声干扰；第二个定理表明，Cs中包含的点的个数小于K个，比最大池化层的维数还要低，也就是说网络对于点集S的预测只依赖于几个典型的特征点Cs，同时K被称作f函数的瓶颈维度。



### 2.5 实验结果

一共可以应用在三个方面有相关的应用：3D object classification, object part segmentation and semantic scene segmentation ，可以理解成点云分类，局部分割和全景分割，前面已经介绍过了。

###### 2.5.1 3D物体分类

3D物体分类：用到了ModelNet40 shape classification数据集，一共有12311个CAD模型，人工分成40个类别，9843的训练集，2468测试集。

在输入数据的时候，我们直接输入原始点云数据，具体操作是在网格面上，根据网格的面积均匀采样1024个点，然后把它们归一化成一个单位球体。在训练过程中，我们也对点云做了数据增强，通过随机沿上轴对物体进行旋转和通过一个平均值为0，标准差为0.02的高斯噪声对每一个点的位置进行抖动。

表一中列出了我们的模型的实验对比图，我们的这个PointNet与之前的网络进行了横向的对比，也与我们自己的baseline网络基本网络做了对比，baseline是对传统特征进行了提。结果显示，不管怎样我们的网络的效果都比较好，而且可以并行在CPU上运行，只有一个例外，就是MVCNN战胜了我们的网络，原因是MUCNN这个网络是基于多视角的方法，我们认为我们的网络不如他们的原因是损失了一些可以被渲染图像捕获的精细几何细节。

![PN-T1](D:/2020hanjia/总结反馈/image/PN-T1.png)

###### 2.5.2 3D目标区域分割

3D目标区域分割：这是一个细粒度的很有挑战性的深度学习课题，是说什么意思呢，给定一个物体，比如一把椅子，要把椅子的每一个部分精确的分割出来。

这个任务用到的是ShapeNet part data set，一共有16881个shape，分成16个种类，这16个种类一共有50个part，大部分的shape是由二至五个part组成的，真实标签表在了每一个shape的采样点上面。

我们把这个任务看成了一各点的分类任务，评价标准是每一个点的mIOU。比如说对于一个shape S，它的类别是C，那么我们计算这个S中的每一个part的IOU，再把它平均，这样就得到了这个shape S的mIOU，如果要计算类别C的mIOU，那么就要把每一个类别是C的shape的mIOU进一步平均。

下表是这个实验的对比图，我们的网络在大部分种类上都超过了其他网络，平均提升2.3%。

![PN-T2](D:/2020hanjia/总结反馈/image/PN-T2.png)

为了试验鲁棒性，我们还在模拟的Kinect上面进行了实验，对于数据集的每一个shape，我们用Blensor Kinect Simulator重新从6个随机视角生成一个不完全的点云图，然后用同样的网络结构去训练完整的或者不完整的点云图，得到的结果只相差了5.3%的mIOU，下图显示的是在完整点云图和不完整点云图上做分割的结果对比。

![PN-F3](D:/2020hanjia/总结反馈/image/PN-F3.png)

###### 2.5.3 语义场景分割

语义场景分割：前面的区域分割可以很容易的拓展到全景分割中，只是把标签从object part labels改成了semantic object classes。

用到的数据集是Stanford 3D semantic parsing dataset，这个数据集是用Matterport 扫描仪扫描出来的一个6个区域271个房间，每一个扫描到的点都标注了1个语义标签，一共13个类别。在训练数据的准备中，首先是把点按照房间进行分类，然后再对一个房间进行采样，采样成1m * 1m的block，然后去预测每一个block的类别，每一个点用一个9维的向量来表示，XYZ，RGB和一个归一化的在房间中处的位置，训练的时候是采样了每一个block中的4096个点，测试的时候是测试了一个block的所有的点，而且用到了k-fold的训练策略。

首先用我们的网络和我们的baseline进行比较，我们的baseline除了使用原来的9维的向量数据外，还包括另外的3维数据，local point density, local curvature and normal  然后用了一个MLP对其进行分类，结果再下表中，两者性能的差别较大，下图是一个结果的可视化。

![PN-T3](D:/2020hanjia/总结反馈/image/PN-T3.png)

![PN-F4](D:/2020hanjia/总结反馈/image/PN-F4.png)

在这个基础之上，我们又建了一个3D目标检测系统，对比算法是基于滑动形状算法，后处理中用到了CRF，用了一个SVM分类器，训练数据是体素格子中的局部几何特征和全局房间纹理特征。对比看到，我们的算法大幅度领先。

![PN-T4](D:/2020hanjia/总结反馈/image/PN-T4.png)

### 2.6 结构设计分析

###### 2.6.1 证明平衡无序性采用的平衡策略的有效性

在4.2.1小节中我们提到了如何处理无序的输入数据集，提到了三种方法，最后选择的maxpooling方法，这一小节就是证明了这个选择很正确。![PN-F5](D:/2020hanjia/总结反馈/image/PN-F5.png)



###### 2.6.2 证明T-net的有效性

从下表中可以看到T-net的加入使有效的，提升了0.8%的准确度，如果再加上之前提到的正则化的手法，将会取得更好的效果。

![PN-T5](D:/2020hanjia/总结反馈/image/PN-T5.png)

###### 2.6.3 鲁棒性测试

在此实验中，用到了一些损失点云信息做测试，当损失50%的点的时候，准确度仅仅下降了2.4%至3.8%；而对于增加一些随机点的情况，鲁棒性依然很好，我们做了两个实验一个是特征设成3维坐标形式，另一个是三维坐标形式外加一个点密度，事实证明，即使有20%的外部点参与，准确度依然可以达到80%以上。

![PN-F6](D:/2020hanjia/总结反馈/image/PN-F6.png)

### 2.7 网络可视化

在图7中，可以很清楚的看到原始点集，重要点集(critical point sets)和上限点集(upper-bound shapes)的对比情况，其中重要点集Cs主要描述出了shape的主要骨架，而上限形状集 Ns则描述出了最大可能的和输入点云有着相同全局特征的点集，Cs和Ns的可视化反映出了整个网络的鲁棒性很强，也解释了失去一些点并不会对网络产生多么大的影响。

![PN-F7](D:/2020hanjia/总结反馈/image/PN-F7.png)

### 2.8 时空复杂性分析

对比算法为MVCNN和Subvolumn两种网络，PointNet和上述两种算法的精确度都很高，但PN的时间复杂度和空间复杂度都是O(N)，是线性增长的，而另外两个网络由于包含卷积层，都是呈平方增长的。

时间复杂度上面，PointNet可以每秒处理超过100万个点的图像分类，大概是1千个物体的检测，或者也可以在全景分割上每秒处理2间屋子，分别领先上述两种算法141倍，8倍；空间复杂度上面，PN只用了350万参数，领先两种算法17倍，4倍；

训练用到的是1080X GPU和tensorflow，实时性上面有了很强的保障。其中PointNet (vanilla)   是表示去掉T-net后的PointNet网络，更为轻便。

![PN-T6](D:/2020hanjia/总结反馈/image/PN-T6.png)

### 2.9 结论

这篇论文提出了一种可以直接运用点云数据的深度神经网络PointNet，可以处理物体分类，物体局部分割和语义全景分割等任务，性能等价或者超过现有的网络结构，我们同时还分析了这个网络，给出了网络的可视化，帮助读者理解这个网络。

## 3 PointNet++

### 3.1 PN++与PN的不同点

PointNet提取特征的方式是对所有点云数据提取了一个全局的特征，显然，这和目前流行的CNN逐层提取局部特征的方式不一样。受到CNN的启发，作者提出了PointNet++，它能够在不同尺度提取局部特征，通过多层网络结构得到深层特征。PointNet++由以下几个关键部分构成：

### 3.2 网络结构介绍

> **采样层（sampling）**
> 激光雷达单帧的数据点可以多达100k个，如果对每一个点都提取局部特征，计算量是非常巨大的。因此，作者提出了先对数据点进行采样。作者使用的采样算法是最远点采样（farthest point sampling, FPS），相对于随机采样，这种采样算法能够更好地覆盖整个采样空间。
>
> **组合层（grouping）**
> 为了提取一个点的局部特征，首先需要定义这个点的“局部”是什么。一个图片像素点的局部是其周围一定曼哈顿距离下的像素点，通常由卷积层的卷积核大小确定。同理，点云数据中的一个点的局部由其周围给定半径划出的球形空间内的其他点构成。组合层的作用就是找出通过采样层后的每一个点的所有构成其局部的点，以方便后续对每个局部提取特征。
>
> **特征提取层（feature learning）**
> 因为PointNet给出了一个基于点云数据的特征提取网络，因此可以用PointNet对组合层给出的各个局部进行特征提取来得到局部特征。值得注意的是，虽然组合层给出的各个局部可能由不同数量的点构成，但是通过PointNet后都能得到维度一致的特征（由上述K值决定）。

上述各层构成了PointNet++的基础处理模块。如果将多个这样的处理模块级联组合起来，PointNet++就能像CNN一样从浅层特征得到深层语义特征。对于分割任务的网络，还需要将下采样后的特征进行上采样，使得原始点云中的每个点都有对应的特征。这个上采样的过程通过最近的k个临近点进行插值计算得到。完整的PointNet++的网络示意图如下图所示。

### 3.3 关键问题处理

不同于图片数据分布在规则的像素网格上且有均匀的数据密度，点云数据在空间中的分布是不规则且不均匀的。虽然PointNet能够用于对各个点云局部提取特征，但是由于点云在各个局部均匀性不一致，很可能导致学习到的PointNet不能提取到很好的局部特征。比如说，在越远的地方激光雷达数据通常变得越稀疏，因此在稀疏的地方应该考虑更大的尺度范围来提取特征。为此，作者提出了两种组合策略来保证更优的特征提取。

> **多尺度组合（multi-scale grouping, MSG）:**
> 比较直接的想法是对不同尺度的局部提取特征并将它们串联在一起，如下图(a)所示。但是因为需要对每个局部的每个尺度提取特征，其计算量的增加也是很显著的。
>
> **多分辨率组合（multi-resolution grouping, MRG）:**
> 为了解决MSG计算量太大的问题，作者提出了MRG。此种方法在某一层对每个局部提取到的特征由两个向量串联构成，如下图(b)所示。第一部分由其前一层提取到的特征再次通过特征提取网络得到，第二部分则通过直接对这个局部对应的原始点云数据中的所有点进行特征提取得到。

## 4 VoxelNet



相应的 time of
shooting 和方向都已经确定了，

常见机械式激光雷达中激光束是波长在900nm左右的近红外光（NIR），可以根据激光直接获得周围一圈的准确的三维空间信息。



这种雷达的成像原理比较简单：发射器和接收器连接在一个可以旋转的机械结构上，某时刻发射器将激光发射出去，之后接收器接收返回的激光并计算激光与物体碰撞点到雷达原点的距离。



由于每次发射/接收的角度是预先设定的，因此根据距离、水平角度和垂直角度就能求出碰撞点相对于激光雷达中心的坐标。每条线每次发射激光得到的数据由一个四元组(x,y,z,i)表示，其中(x,y,z)是三维坐标，i表示反射强度。

以某款32线激光雷达为例，32根线从上到下排列覆盖15.0°到-24.9°。



工作状态时这32根线在水平平面旋转可以采集一周360°的数据。雷达的旋转速度和角分辨率是可以调节的，常用速度为10hz（100ms转一圈）对应每0.2°采集一次数据，即角分辨率为360/0.2=1800。



由于光速非常快所以在1800中任何一个位置进行一次发射和接收动作可以看作是瞬时完成的。受到硬件能力的限制，一般转速越快则发射和接收激光的次数越少，即角分辨率越小。常用雷达采集到的数据点距离雷达中心一般不会超过150米。



通常 采集到的360°的数据被称为一帧，上面的例子中一帧数据在理论上最多包含32*(360/0.2)=57600个点。



在实际情况中如果雷达被放置在车的上方大约距地面1.9米的位置，则在比较空旷的场景中大约获得40000个点，一部分激光点因为被发射向天空或被吸收等并没有返回到接收器，也就无法得到对应的点。下图是典型的一帧数据的可视化图。

现在在激光雷达数据目标检测中最常用的算法是基于深度学习的算法，其效果与传统学习算法相比要好很多，其中很多算法都采用了与图片目标检测相似的算法框架。



早期的激光点云上的目标检测和图片上的目标检测算法并不一样，图片数据上常见的HOG、LBP和ACF【10，11，12】等算法并没有应用到点云数据中。



这是因为激光点云数据与图片具有不同的特点，反过来图片中也并不存在上节中讨论的点云的很多特点。



从2014年开始随着RCNN、Fast RCNN、Faster RCNN、YOLO和SSD【1，2，3，4，5，6，7】等图片目标检测算法的进步，研究者对于检测算法的理解也在不断深入。



研究者发现虽然点云数据与图片数据有很多不一样的特点，但是在鸟瞰图中这两种不同的数据在目标检测的框架下具有相通之处，因此基于鸟瞰图的激光点云的目标检测算法几乎都沿用了图片目标检测算法的思路。



2016年PointNet【8】提出了另外的一种算法框架，其提出了一种在三维空间中与点云顺序无关的算子并结合CNN也在目标分割和识别上得到了很好的效果。



这个方法为三维点云中的目标检测提供了新的思路，即有可能存在一种比基于鸟瞰图算法通用的三维目标检测方法。



如前文所述激光点云数据有一些无法克服的问题，其中最主要的就是稀疏性。提高雷达的线数是一个解决问题的途径，但是现有高线数雷达的成本过高很难真正落地，并且高线数也无法从根本上解决远距离的稀疏问题。



为了解决这个问题一些研究者提出了激光数据和图片数据相融合的方法，这种方法尤其对小物体和远处的物体有很好的效果。



激光点云中目标检测的结果的稳定性也十分重要，传统的检测算法并不特别关注这个问题，其中一个原因是在后续的跟踪和关联算法中可以对检测到的目标的大小、尺寸进行滤波，从而得到稳定的结果。



近几年一些研究者尝试将“稳定算法输出”的任务交给深度神经网络，尝试根据连续的多帧数据对当前帧进行检测，这种方法可以增加算法输出结果的稳定性，减少后续跟踪算法的复杂程度，提高整个系统的鲁棒性。



接下来会介绍一些在基于单帧激光数据、图片和激光融合以及基于连续多帧激光数据这三个方面具有代表性的算法。